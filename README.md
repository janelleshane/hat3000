# hat3000
Short description: a big set of crochet patterns generated using a finetuned GPT-2

If you aren’t familiar with this project already, please be aware: this collection of patterns is not going to create tidy finished hats. In fact, some of the "hat patterns" are more like world-devouring traps, a cascading series of hyperbolic increases that will devour your favorite yarn, your excess yarn, your neighbor's yarn... it has not been tested, but it is entirely possible that some of them would consume all the yarn that humanity has ever produced. 

These patterns were produced by a computer algorithm (we’ll call it HAT3000) called a recurrent neural network. Like its predecessor SkyKnit (which specialized in weird knitting patterns) This kind of algorithm learns by example - give it a few thousand examples of something, and it’ll figure out the rules that will let it generate more. 

Unlike SkyKnit, HAT3000 did not start from an entirely blank slate. Instead, HAT3000 is a descendant of 345M-GPT-2, a neural network that OpenAI trained on a huge set of pages sampled from across the internet. From this starting point, we trained HAT3000 on a list of 500 example crochet hat patterns. Within minutes, HAT3000 was producing things that resembled crochet hat patterns. Loosely resembled them, anyways.

This is a collection of 100+ patterns created by HAT3000. Please do not expect instructions for a series of workable items. In many cases, the patterns cut out mid-row - this is due to the limited length of text samples that HAT3000 can export. For each text sample (separated by a row of = signs), the first sentence was supplied by a human, in an attempt to start HAT3000 off in an interesting direction. You may notice that HAT3000 still remembers how to generate Harry Potter fanfiction, recipes, and more - but that it usually tries its best to artfully bend the story toward the subject of crochet hats. Occasionally you may come across an <endoftext> tag; this is when HAT3000 switches on its own to unprompted text, which may be more crochet patterns or may be even more erratic text. 

NB: some of the patterns themselves may be NSFW, which is why there is an adult-content warning. HAT3000 is descended from a neural network that was trained on a general swath of the internet, which means it was also trained on some very NSFW and/or offensive content. HAT3000 has abandoned that kind of content in favor of crochet hats - but not altogether entirely. Explicit text may still occasionally pop up in these patterns, which have not been prefiltered by human eyes.

Many of these patterns have been tried by the adventurous (and NSFW) crocheters here (registration and group membership required): https://www.ravelry.com/discuss/lazy-stupid-and-godless/3775834/1-25

Anyone who actually manages to crochet one of these monstrosities can do what they like with it. Adapt it, sell the product, sell the adapted pattern, turn it into weird lingerie - it’s all good. With one or two exceptions, the HAT3000 patterns aren’t doable without at least some debugging, and each crocheter’s solutions makes the product look completely different.

A HUGE thanks to these awesome designers who gave permission for HAT3000 to learn from their patterns! Any world-eating or obscenity-generating tendencies of the resulting algorithm are definitely not their fault. (All other patterns in the training set were public-domain)

https://www.ravelry.com/patterns/sources/krisitis-patterns
https://www.ravelry.com/people/irishlacenet
https://www.ravelry.com/people/SierraPelona
https://www.ravelry.com/people/fairyhedgehogg
https://www.ravelry.com/people/watrpriestess
https://www.ravelry.com/people/RachyNewin
https://www.ravelry.com/people/agnosticnun
https://www.ravelry.com/people/UnplannedCauli
https://www.ravelry.com/people/membril
http://mooglyblog.com/
https://www.ravelry.com/people/SuviCrochets

And thank you to Max Woolf for turning GPT-2 into an easy-to-use colaboratory notebook.
https://github.com/minimaxir/gpt-2-simple
If HAT3000's patterns devour the universe, it is not his fault either.

